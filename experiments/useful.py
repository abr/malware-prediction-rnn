import os.path
import numpy as np
import keras.backend as K
from keras import callbacks

np.random.seed(11)

def unison_shuffled_copies(arrays):
	"""shuffle multiple arrays keeping corresponding indicies in the same way"""
	length = len(arrays[1])
	for x in arrays:
		assert len(x) == length
	p = np.random.permutation(length)
	return tuple([x[p] for x in arrays])

def get_mean_and_stdv(dataset):
	"""return means and standard deviations along 0th axis of tensor"""
	means = dataset.mean(0)
	stdvs = dataset.std(0)
	return means, stdvs

def scale_array(dataset, means, stdvs):
	"""normalise by means and standard deviations along 0th axis of tensor"""
	return (dataset - means) / (stdvs + K.epsilon())

def check_filename(originalName):
	""" add number to filename to make unique if not already - returns new name"""
	count = 1
	exists = True
	fileName = originalName
	while(exists):
		exists = os.path.exists(fileName)
		if exists:
			if "." in originalName:
				fileName = originalName.split(".")
				fileName[0] += "_" + str(count)
				fileName = ".".join(fileName)
			else: 
				fileName = originalName + "_" + str(count)
			count += 1
	return fileName

def __to_numpy_tensors(self, x, y):
	""" return x and y as numpy tensors, x as a 3-D tensor, y as a 2-D tensor"""
	x_shape = (len(x), len(x[0]), len(x[0][0]))
	y_shape = (len(y), 1)
	
	if type(x) is list:
		x = np.array(x)
	if type(y) is list:
		y = np.array(y)

	x = x.reshape(tuple(x_shape))
	y = y.reshape(tuple(y_shape))

	return x, y

def remove_short(dataX, dataY, length):
	"""Remove any seqences in dataX shorter than length, crop any longer than length, return new X and Y tensors"""
	new_X = []
	new_Y = []

	for x in list(range(len(dataX))):
		if len(dataX[x]) >= length:
			new_X.append(dataX[x][:length])
			new_Y.append(dataY[x][:length])

	return __to_numpy_tensors(new_X, new_Y)

def remove_short_idx(dataX, dataY, idxs, length):
	new_X = []
	new_Y = []
	new_idxs = []
	
	for x in list(range(len(dataX))):
		if len(dataX[x]) >= length:
			new_X.append(dataX[x][:length])
			new_Y.append(dataY[x][:length])
			new_idxs.append(idxs[x])

	return __to_numpy_tensors(new_X, new_Y), np.array(new_idxs)


def timestamped_to_vector(data, timestamp_col, time_start, classification_col):
	"""Return tuple of inputs and outputs)
	Removes timestamp - not desirable if irregular inputs
	"""
	x = []
	y = []
	temp_inputs = []
	temp_outputs = []
	for input_row in data:
		#print([np.round(x) for x in input_row])
		if (input_row[timestamp_col] == time_start):
			if (temp_inputs != [] and temp_outputs != []):
				x.append(temp_inputs)
				y.append(temp_outputs)
				temp_inputs = []
				temp_outputs = []
		temp_inputs.append(
			remove_items(input_row.tolist(), [classification_col, timestamp_col])
		)
		temp_outputs = [int(input_row[classification_col])]

	if (temp_inputs != [] and temp_outputs != []):
		x.append(temp_inputs)
		y.append(temp_outputs)

	x = np.asarray(x)
	y = np.asarray(y)
	return x, y


last_one = 0
def to_chunks(l, num_chunks):
	global last_one
	chunks = []
	n = len(l)//num_chunks

	#Most samples spread out
	for i in range(0, n*num_chunks, n):
		chunks.append(l[i:i + n])
	
	#Extras distributed evenly:
	for i in range(n*num_chunks, len(l)):
		chunks[last_one].append(l[i])
		last_one = (last_one + 1) % num_chunks
		
	last_one = 0
	return chunks


def merge_two_dicts(x, y):
    """Given two dicts, merge them into a new dict as a shallow copy. Credit: http://stackoverflow.com/questions/38987/how-to-merge-two-python-dictionaries-in-a-single-expression"""
    z = x.copy()
    z.update(y)
    return z

class ResetStatesCallback(callbacks.Callback):
	def __init__(self):
		self.current_epoch = 0

	def on_batch_begin(self, batch, logs={}):
		self.model.reset_states()