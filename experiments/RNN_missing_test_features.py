	def leave_out_data():
		#Write up predictions......
		

		pred_file = open(self.folder_name + "/predictions_{}.csv".format(self.current_params["sequence_length"]), "w")
		headers = ["Time","DB_totalpro","DB_maxPID","DB_CPUUser","DB_CPUSys","DB_memUse","DB_swapUse","DB_RXPac","DB_TXPac","DB_RXByte","DB_TXByte","pred","truth","idx", "value", "accuracy", "expt_id"]
		headers = headers + [x + "_STATE" for x in headers[:len(self.x_test[0][0])]]
		pred_file.write(",".join(headers) + "\n")

		indicies = list(range(len(self.x_test[0][0])))

		temp_id = 0

		for feature_set in range(1, len(indicies) + 1):
			for subset in itertools.combinations(indicies, feature_set):
				means = "means"
				temp_test_X = deepcopy(self.x_test)
				states = [1 for x in range(len(indicies))]
				for feature_index in subset:
					states[feature_index] = 0
					temp_test_X[:,:,feature_index] = 0 # because 0 is the mean of the training data
			
				start_predict = time.time()
				__pred_Y = model.predict(temp_test_X, batch_size=self.current_params["batch_size"]) #Predicted value of Y
				ttime = time.time() - start_predict
				self.metrics['test_time'] = ttime
				pred_Y = [x[0] for x in __pred_Y]
				Y_classes =  [np.round(x) for x in pred_Y] #Choose a class
				self.metrics["preds"] = pred_Y
				self.metrics["categorical_preds"] = Y_classes
				self.metrics["truths"] = [int(x[0]) for x in self.y_test]
				self.metrics["variance"] = np.var(pred_Y)

				acc = accuracy_score(self.metrics["truths"], self.metrics["categorical_preds"])
				print("acc", subset, accuracy_score(self.metrics["truths"], self.metrics["categorical_preds"]))
				
				for i, sample in enumerate(temp_test_X.tolist()):
					pred = self.metrics["preds"][i]
					truth = self.metrics["truths"][i]
					row = sample[0] + [pred, truth, i, 0, acc, temp_id] + states
					row = [str(x) for x in row]
					pred_file.write(",".join(row) + "\n")

				temp_id += 1

		pred_file.close()